{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-ray Analysis for Pneumonia Detection\n",
    "\n",
    "### Team : FInal Project 16\n",
    "| Student No  | First Name                  | Last Name     |\n",
    "|-------------|-----------------------------|---------------|\n",
    "| 9016986     | Keerthi                     | Gonuguntla    |\n",
    "| 8965985     | Pradeepti                   | Kasam         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Dense, Dropout, Input,GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train, Test, validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the  data set folders\n",
    "base_path = r\"Data Set\"\n",
    "\n",
    "# creating the Folders for normal and pneumonia data for splitting of the data \n",
    "categories = [\"normal\", \"pneumonia\"]\n",
    "\n",
    "# Creating Output directories for train, test, validation splits\n",
    "output_dir = os.path.join(\"Final DataSet\")\n",
    "splits = [\"train\", \"test\", \"val\"]\n",
    "\n",
    "# Creating output directories for splitting the data \n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n",
    "\n",
    "# Split ratio of the dataset \n",
    "train_ratio = 0.6\n",
    "test_val_ratio = 0.4\n",
    "test_ratio = 0.5  \n",
    "\n",
    "# Initializing counters for the split sizes\n",
    "split_sizes = {\"train\": 0, \"test\": 0, \"val\": 0}\n",
    "\n",
    "# Initializing total image counters\n",
    "total_normal_images = 0\n",
    "total_pneumonia_images = 0\n",
    "\n",
    "# Printing the number of images before splitting\n",
    "print(\"Before splitting:\")\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Directory not found: {category_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get list of all image files in the category folder\n",
    "    files = os.listdir(category_path)\n",
    "    files = [f for f in files if os.path.isfile(os.path.join(category_path, f))]\n",
    "    category_image_count = len(files)\n",
    "    \n",
    "    # Add to total counts\n",
    "    if category == \"normal\":\n",
    "        total_normal_images = category_image_count\n",
    "    elif category == \"pneumonia\":\n",
    "        total_pneumonia_images = category_image_count\n",
    "    \n",
    "    print(f\"{category.capitalize()} images before splitting: {category_image_count}\")\n",
    "\n",
    "# Printing the total images in both categories before splitting\n",
    "total_images = total_normal_images + total_pneumonia_images\n",
    "print(f\"\\nTotal images before splitting: {total_images}\")\n",
    "\n",
    "# Splitting the images into train, test, and validation\n",
    "for category in categories:\n",
    "    category_path = os.path.join(base_path, category)\n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"Directory not found: {category_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Get list of all image files in the category folder\n",
    "    files = os.listdir(category_path)\n",
    "    files = [f for f in files if os.path.isfile(os.path.join(category_path, f))]\n",
    "\n",
    "    # Splitting the data into train and temp -> for test and validation\n",
    "    train_files, temp_files = train_test_split(files, test_size=test_val_ratio, random_state=42)\n",
    "\n",
    "    # Splitting temp_files into test and validation sets\n",
    "    val_files, test_files = train_test_split(temp_files, test_size=test_ratio, random_state=42)\n",
    "\n",
    "    # Moving files into respective folders and count the number of images \n",
    "    for file_list, split in [(train_files, \"train\"), (test_files, \"test\"), (val_files, \"val\")]:\n",
    "        for file in file_list:\n",
    "            src = os.path.join(category_path, file)\n",
    "            dst = os.path.join(output_dir, split, category, file)\n",
    "\n",
    "            # Move the file to the appropriate folder\n",
    "            shutil.copy(src, dst)\n",
    "            split_sizes[split] += 1\n",
    "\n",
    "# Printing the number of images after splitting\n",
    "print(\"\\nAfter splitting:\")\n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        category_split_path = os.path.join(output_dir, split, category)\n",
    "        if os.path.exists(category_split_path):\n",
    "            split_count = len(os.listdir(category_split_path))\n",
    "            print(f\"{split.capitalize()} {category.capitalize()} images: {split_count}\")\n",
    "\n",
    "# Printing the size of each data set\n",
    "print(f\"\\nTrain size: {split_sizes['train']}\")\n",
    "print(f\"Test size: {split_sizes['test']}\")\n",
    "print(f\"Validation size: {split_sizes['val']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Exploration\n",
    "\n",
    "* Examines the structure of the dataset: To verify that the data is arranged into train, test, and val directories, it prints the folder hierarchy.\n",
    "\n",
    "* Illustrates the appearance of the data by displaying a few pictures from each group (normal vs pneumonia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the train,test, validation Data Set \n",
    "base_path = \"Final DataSet\"\n",
    "splits = ['train', 'test', 'val']\n",
    "categories = ['normal', 'pneumonia']\n",
    "\n",
    "# Function to print the number of files in a directory\n",
    "def count_images_in_folder(path):\n",
    "    return len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])\n",
    "\n",
    "# Function to visualize the first 5 images in each folder\n",
    "def visualize_images(split, category):\n",
    "    # Get the path for the images in the specific split and category\n",
    "    images_path = os.path.join(base_path, split, category)\n",
    "    image_files = os.listdir(images_path)[:5]  \n",
    "\n",
    "    # Plotting the images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, image_name in enumerate(image_files):\n",
    "        img_path = os.path.join(images_path, image_name)\n",
    "        img = mpimg.imread(img_path)  # Reading the image\n",
    "        \n",
    "        plt.subplot(1, 5, i + 1)  # Arranging the images in one row with 5 columns\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  \n",
    "        plt.title(image_name)  # Printing the image filename as the title\n",
    "        \n",
    "    plt.show() #Printing the images \n",
    "\n",
    "# Inspect the dataset structure and print the number of images before visualization\n",
    "print(\"Dataset Structure (Before Visualization):\")\n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        images_path = os.path.join(base_path, split, category)\n",
    "        image_count = count_images_in_folder(images_path)\n",
    "        print(f\"{split.capitalize()} - {category.capitalize()} images: {image_count}\")\n",
    "\n",
    "# Visualizing the first 5 images for each category in each split\n",
    "print(\"\\nVisualizing the first 5 images for each category and split:\")\n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        print(f\"\\n{split.capitalize()} - {category.capitalize()} images:\")\n",
    "        visualize_images(split, category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing\n",
    "\n",
    "We are applying a number of processes to the images in order to preprocess the dataset for chest X-ray pneumonia detection model. \n",
    "\n",
    "#### Steps for Preprocessing:\n",
    "\n",
    "1. Convert images to grayscale (if required):\n",
    "\n",
    "* Here in this step we will need to convert any colorful images in dataset to grayscale. However, unless dataset contains colorful images, this might not be required because chest X-ray scans are typically already in grayscale.\n",
    "\n",
    "2. Resize images to a consistent size (224x224):\n",
    "\n",
    "* All photos must be resized to the models needed input size, which for many pre-trained models (such as VGG16) is often 224x224.\n",
    "\n",
    "3. Normalize pixel values to the range [0, 1]:\n",
    "\n",
    "* Images usually have pixel values between 0 and 255.Here we are dividing the pixel values by 255 in order to normalize them to a range of [0, 1] for deep learning models.\n",
    "\n",
    "4. Augment data using transformations such as flipping, rotation, and zoom:\n",
    "\n",
    "* By artificially expanding the training set diversity, data augmentation can aid in enhancing the model resilience. we are performing arbitrary flips, zooms, and rotations.\n",
    "\n",
    "#### Code Implementation for Preprocessing:\n",
    "\n",
    "The Keras library will be used for simple picture augmentation and preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Creating an ImageDataGenerator for training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0,1]\n",
    "    rotation_range=20,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random horizontal shift\n",
    "    height_shift_range=0.2,  # Random vertical shift\n",
    "    horizontal_flip=True,  # Random horizontal flip\n",
    "    zoom_range=0.2  # Random zoom\n",
    ")\n",
    "\n",
    "# Creating an ImageDataGenerator for validation and test data -> only rescaling\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setting up generators for train split\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, 'train'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',  # Converting each image to grayscale\n",
    "    shuffle=False  # Disabling shuffling to get the same images\n",
    ")\n",
    "\n",
    "# Setting up generators for Validation split\n",
    "validation_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, 'val'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "# Setting up generators for test split\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, 'test'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# created a Function to preprocess a single image\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path, color_mode='grayscale', target_size=(img_width, img_height))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# created a Function to display sample images from both classes\n",
    "def display_images(generator, num_images=5, is_augmented=False):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    images, labels = next(generator)\n",
    "    class_0_count = class_1_count = 0\n",
    "    i = 0\n",
    "    while class_0_count < num_images or class_1_count < num_images:\n",
    "        if i >= len(images):\n",
    "            images, labels = next(generator)\n",
    "            i = 0\n",
    "        image = images[i]\n",
    "        label = labels[i]\n",
    "        if (label == 0 and class_0_count < num_images) or (label == 1 and class_1_count < num_images):\n",
    "            ax = plt.subplot(2, num_images, (1 if label == 0 else num_images+1) + (class_0_count if label == 0 else class_1_count))\n",
    "            if is_augmented:\n",
    "                image = train_datagen.random_transform(image)\n",
    "            plt.imshow(image.reshape(img_width, img_height), cmap='gray')\n",
    "            plt.title(f\"Class: {labels[i]}\")\n",
    "            plt.axis('off')\n",
    "            if label == 0:\n",
    "                class_0_count += 1\n",
    "            else:\n",
    "                class_1_count += 1\n",
    "        i += 1\n",
    "    plt.show() # Displaying the images\n",
    "\n",
    "\n",
    "# Displaying sample preprocessed and augmented images from the training set\n",
    "print(\"Sample preprocessed images from the training set:\\n\")\n",
    "display_images(train_generator)\n",
    "print(\"Sample augmented images from the training set:\")\n",
    "display_images(train_generator, is_augmented=True)\n",
    "\n",
    "# Displaying sample preprocessed and augmented images from the validation set\n",
    "print(\"Sample preprocessed images from the validation set:\")\n",
    "display_images(validation_generator)\n",
    "print(\"Sample augmented images from the validation set:\")\n",
    "display_images(validation_generator, is_augmented=True)\n",
    "\n",
    "# Displaying sample preprocessed and augmented images from the test set\n",
    "print(\"Sample preprocessed images from the test set:\")\n",
    "display_images(test_generator)\n",
    "print(\"Sample augmented images from the test set:\")\n",
    "display_images(test_generator, is_augmented=True)\n",
    "\n",
    "# Printing the class indices\n",
    "print(\"\\nClass indices:\")\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "# Printing the shape of the data\n",
    "print(\"\\nShape of the data:\")\n",
    "print(f\"Input shape: {train_generator.image_shape}\")\n",
    "\n",
    "# Displaying the sample preprocessed image from each class\n",
    "for class_name in ['normal', 'pneumonia']:\n",
    "    sample_img_path = os.path.join(base_path, 'train', class_name, os.listdir(os.path.join(base_path, 'train', class_name))[0])\n",
    "    preprocessed_img = preprocess_image(sample_img_path)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(preprocessed_img.reshape(img_width, img_height), cmap='gray')\n",
    "    plt.title(f\"Sample Preprocessed {class_name.capitalize()} Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a CNN Model\n",
    "\n",
    "To build a CNN model for chest X-ray classification, we can use either a custom CNN or transfer learning with a pre-trained model. Here are implementations for both options using TensorFlow/Keras:\n",
    "\n",
    "#### 1: Custom CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn(input_shape=(224, 224, 1)):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "custom_model = create_custom_cnn()\n",
    "custom_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(input_shape=(224, 224, 3)):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "transfer_model = create_transfer_learning_model()\n",
    "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2  # 20% validation split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'Final DataSet/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'Final DataSet/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_custom_cnn_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = custom_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "tensorflow_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
